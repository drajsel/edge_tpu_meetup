{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time person detection with Tensorflow\n",
    "\n",
    "Let's do something similar with Tensorflow on CPU/GPU and compare the performance. Note that this is not the fastest implementation possible, but it is one that requires about the same effort as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import InteractiveSession, ConfigProto\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an object detection model. In this demo we will get a generic object detection model and we will detect persons. This will be slower (due to more detections), but it will be provide a comparison between the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-06 11:30:33--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.22.80, 172.217.16.144, 2a00:1450:401b:805::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.22.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 187925923 (179M) [application/x-tar]\n",
      "Saving to: ‘data/ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_co 100%[===================>] 179,22M  14,0MB/s    in 7,8s    \n",
      "\n",
      "2019-05-06 11:30:41 (23,1 MB/s) - ‘data/ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_coco_2018_03_29/checkpoint\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.meta\n",
      "ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/saved_model/variables/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.index\n",
      "ssd_mobilenet_v2_coco_2018_03_29/\n",
      "ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar zxvf data/ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the graph and load the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile('ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb', 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Set the input/output tensors\n",
    "    tensor_dict = {}\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "    tensor_dict['detection_boxes'] = tf.get_default_graph().get_tensor_by_name('detection_boxes:0')\n",
    "    tensor_dict['detection_classes'] = tf.get_default_graph().get_tensor_by_name('detection_classes:0')\n",
    "    tensor_dict['detection_scores'] = tf.get_default_graph().get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf\", 20, encoding=\"unic\")\n",
    "    cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the face detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "with detection_graph.as_default():\n",
    "    while (True):\n",
    "        # Run inference.\n",
    "        start_time = time()\n",
    "\n",
    "        # Get the frame\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        # Convert to PIL image\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_im = Image.fromarray(rgb_frame)\n",
    "        draw = ImageDraw.Draw(pil_im)\n",
    "\n",
    "        # Run the detection\n",
    "        image_np_original = np.asarray(pil_im).astype(np.uint8)\n",
    "        new_img = pil_im.copy()\n",
    "        new_img.thumbnail((320, 320), Image.ANTIALIAS)\n",
    "        image_np = np.asarray(new_img).astype(np.uint8)\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "        # Run inference\n",
    "        start_time_inference = time()\n",
    "        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\n",
    "        end_time_inference = time()\n",
    "\n",
    "        boxes, scores = output_dict['detection_boxes'][0], output_dict['detection_scores'][0]\n",
    "        classes = output_dict['detection_classes'][0].astype(np.int64)\n",
    "\n",
    "        # Get the results\n",
    "        for box, score, label in zip(boxes, scores, classes):\n",
    "            if score > 0.1 and label == 1:  # Labels 1 corresponds to person\n",
    "                [ymin, xmin, ymax, xmax] = box\n",
    "                im_height, im_width, _ = image_np_original.shape\n",
    "                draw.rectangle((xmin * im_width, ymax * im_height, xmax * im_width, ymin * im_height),\n",
    "                               outline='red', width=4, )\n",
    "        end_time = time()\n",
    "        \n",
    "        # Calculate some statistics\n",
    "        fps = 1. / (end_time - start_time)\n",
    "        fps_inf = 1. / (end_time_inference - start_time_inference)\n",
    "        draw.text((0, 0), 'FPS:  %3.2f , Inference FPS:  %3.2f' % (fps, fps_inf), font=font)\n",
    "\n",
    "        bgr_frame = cv2.cvtColor(np.array(pil_im), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('frame', bgr_frame)\n",
    "\n",
    "        # Quit on q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
