{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the basics\n",
    "\n",
    "Let's train a simple CNN using tensorflow. Note that quantization aware training should be used to ensure that the model will perform as intended after the quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow import InteractiveSession, ConfigProto\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(x, training=False):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "    x = tf.layers.conv2d(x, 32, 3, activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(x, 2, 2)\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, 3, activation=tf.nn.relu)\n",
    "    x = tf.layers.max_pooling2d(x, 2, 2)\n",
    "\n",
    "    x = tf.layers.dropout(x, rate=0.5, training=training)\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    x = tf.layers.dense(x, 1024, activation=tf.nn.relu)\n",
    "    x = tf.layers.dropout(x, rate=0.5, training=training)\n",
    "    x = tf.layers.dense(x, 10)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='input')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "logits = cnn_model(x, True)\n",
    "y_pred = tf.nn.softmax(logits, name='prob')\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_pred))\n",
    "\n",
    "# Add fake quantization nodes\n",
    "tf.contrib.quantize.create_training_graph(quant_delay=2000)\n",
    "\n",
    "# Setup the optimizer\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "train_step_fine = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "Test acc =  0.9555\n",
      "Test acc =  0.9725\n",
      "Test acc =  0.9718\n",
      "Test acc =  0.9792\n",
      "Test acc =  0.978\n",
      "Test acc =  0.9795\n",
      "Test acc =  0.9819\n",
      "Test acc =  0.9835\n",
      "Test acc =  0.9797\n",
      "Test acc =  0.9853\n",
      "Test acc =  0.9858\n",
      "Test acc =  0.9875\n",
      "Test acc =  0.9871\n",
      "Test acc =  0.9855\n",
      "Test acc =  0.988\n",
      "Test acc =  0.988\n",
      "Test acc =  0.9867\n",
      "Test acc =  0.9881\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST-data', one_hot=True)\n",
    "\n",
    "for i in range(10 * 60000//128):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i + 1) % 500 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test acc = \", acc)\n",
    "\n",
    "for i in range(10 * 60000//128):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    sess.run(train_step_fine, feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i + 1) % 500 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test acc = \", acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/trained_model.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'data/trained_model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
